{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgo-oaI3JU2u"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/justinjohn0306/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "!pip install ffmpeg-python\n",
        "\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from base64 import b64encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDHxFarmO_ra"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqnvYvMmQBlx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import moviepy.editor as mp\n",
        "\n",
        "def split_video_audio(input_video, input_audio, segment_length):\n",
        "    video = mp.VideoFileClip(input_video)\n",
        "    audio = mp.AudioFileClip(input_audio)\n",
        "\n",
        "    total_duration = audio.duration\n",
        "    num_segments = int(total_duration / segment_length) + 1\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "\n",
        "        segment_video = video.subclip(start_time, end_time)\n",
        "        segment_audio = audio.subclip(start_time, end_time)\n",
        "\n",
        "        segment_video.write_videofile(f\"segment_{i}.mp4\", codec=\"libx264\", audio=False)\n",
        "        segment_audio.write_audiofile(f\"segment_{i}.wav\")\n",
        "\n",
        "    video.close()\n",
        "    audio.close()\n",
        "\n",
        "# Usage example\n",
        "input_video = \"/content/drive/MyDrive/video.mp4\"\n",
        "input_audio = \"/content/drive/MyDrive/audio.wav\"\n",
        "segment_length = 60  # in seconds\n",
        "\n",
        "split_video_audio(input_video, input_audio, segment_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgtO08V28ANf"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/segment_0.mp4\" --audio \"/content/segment_0.wav\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

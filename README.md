# Audio_Video_sync

# Lip Sync Project using Wav2lip

This project demonstrates how to synchronize audio and video using Wav2lip, an automatic lip-sync algorithm. Wav2lip is capable of generating realistic lip movements for a given audio input, making it useful for applications such as video dubbing, deepfake videos, and more.

## Getting Started

### Prerequisites

- Python 3.7 or above
- ffmpeg (for video and audio processing)

### Usage
Prepare your input files:

Video: Place your input video file in the project directory.
Audio: Place your input audio file in the project directory. Make sure it has the same duration as the video or is shorter.

Run the <b>main.ipynb</b> file on google colab.

### Note
- Please change the location of input video and audio file as per your convinience in <b> Split_video_audio Function<b/>
- The output will be named <b>result_voice.mp4</b> at <b>Wav2lip/results</b>.

### Acknowledgments
This project is based on the Wav2lip repository by Rudrabha Mukhopadhyay. Make sure to check out their repository for more information on Wav2lip and additional features.
License
Include information about the license under which this project is released.

### Contributing
Provide guidelines for other developers who want to contribute to the project. Include information about pull requests, issue tracking, and coding standards.
